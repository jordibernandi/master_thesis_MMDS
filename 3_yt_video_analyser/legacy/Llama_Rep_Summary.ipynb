{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e79678e7-897c-492c-b8c2-de0efc2738ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install bertopic accelerate bitsandbytes xformers adjustText\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance, TextGeneration\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "import hdbscan\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6efc4f23-d838-423e-aed1-59c0722533a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5714, 22)\n",
      "(5726, 22)\n"
     ]
    }
   ],
   "source": [
    "# Load JSON files\n",
    "with open('summarized_BEFORE_COVID.json', 'r') as file:\n",
    "    before_covid_data = json.load(file)\n",
    "\n",
    "with open('summarized_AFTER_COVID.json', 'r') as file:\n",
    "    after_covid_data = json.load(file)\n",
    "\n",
    "# Convert to DataFrame\n",
    "before_covid_df = pd.json_normalize(before_covid_data)\n",
    "after_covid_df = pd.json_normalize(after_covid_data)\n",
    "\n",
    "print(before_covid_df.shape)\n",
    "print(after_covid_df.shape)\n",
    "\n",
    "# Extract necessary columns\n",
    "texts_before = before_covid_df[['summary', 'channel.ideology']]\n",
    "texts_after = after_covid_df[['summary', 'channel.ideology']]\n",
    "\n",
    "# Get unique ideologies\n",
    "ideologies = texts_before['channel.ideology'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8140c34-51c5-4285-b6d7-bd27a0cf157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_before = texts_before[texts_before['channel.ideology'] == \"BLACK\"]\n",
    "texts_after = texts_after[texts_after['channel.ideology'] == \"BLACK\"]\n",
    "\n",
    "# List of ideologies\n",
    "ideologies = [\"BLACK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4b297d2-b4d4-4c9f-8ae9-4c83514e0a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# def clean_text(text):\n",
    "#      # Remove non-ascii characters\n",
    "#     text = text.encode(\"ascii\", \"ignore\").decode()\n",
    "\n",
    "#     # Remove newlines and extra spaces\n",
    "#     text = text.replace('\\n', ' ').replace('\\r', ' ').strip()\n",
    "\n",
    "#     # Tokenize the text into sentences\n",
    "#     sentences = sent_tokenize(text)\n",
    "\n",
    "#     # Define unnecessary punctuation to remove\n",
    "#     unnecessary_punctuation = r'[“”\\'`~]'\n",
    "    \n",
    "#     # Remove unnecessary punctuation and special characters\n",
    "#     cleaned_sentences = [re.sub(unnecessary_punctuation, '', sentence) for sentence in sentences]\n",
    "\n",
    "#     # Optionally convert text to lowercase (comment this line if you want to keep the original case)\n",
    "#     # cleaned_sentences = [sentence.lower() for sentence in cleaned_sentences]\n",
    "\n",
    "#     # Join the cleaned sentences back into a single string\n",
    "#     cleaned_text = ' '.join(cleaned_sentences)\n",
    "\n",
    "#     return cleaned_text\n",
    "\n",
    "# # Assuming texts_before and texts_after are pandas DataFrames\n",
    "# texts_before['transcripts'] = texts_before['transcripts'].apply(clean_text)\n",
    "# texts_after['transcripts'] = texts_after['transcripts'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e65ea14-f679-4724-afc9-e097a3559ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average token size for texts_before: 231.44273127753303\n",
      "Average token size for texts_after: 228.0625\n",
      "Max token size for texts_before: 452\n",
      "Max token size for texts_after: 435\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to calculate average token size\n",
    "def get_average_token_size(texts, tokenizer):\n",
    "    total_tokens = 0\n",
    "    total_texts = len(texts)\n",
    "    \n",
    "    for text in texts:\n",
    "        tokens = tokenizer.encode(text, add_special_tokens=True)\n",
    "        total_tokens += len(tokens)\n",
    "    \n",
    "    average_size = total_tokens / total_texts if total_texts > 0 else 0\n",
    "    return average_size\n",
    "\n",
    "# Calculate average token size for texts_before and texts_after\n",
    "average_token_size_before = get_average_token_size(texts_before['summary'], tokenizer)\n",
    "average_token_size_after = get_average_token_size(texts_after['summary'], tokenizer)\n",
    "\n",
    "print(f'Average token size for texts_before: {average_token_size_before}')\n",
    "print(f'Average token size for texts_after: {average_token_size_after}')\n",
    "\n",
    "# Function to calculate max token size\n",
    "def get_max_token_size(texts, tokenizer):\n",
    "    max_size = 0\n",
    "    for text in texts:\n",
    "        tokens = tokenizer.encode(text, add_special_tokens=True)\n",
    "        max_size = max(max_size, len(tokens))\n",
    "    return max_size\n",
    "\n",
    "# Calculate max token size for texts_before and texts_after\n",
    "max_token_size_before = get_max_token_size(texts_before['summary'], tokenizer)\n",
    "max_token_size_after = get_max_token_size(texts_after['summary'], tokenizer)\n",
    "\n",
    "print(f'Max token size for texts_before: {max_token_size_before}')\n",
    "print(f'Max token size for texts_after: {max_token_size_after}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f499898-fe38-4f61-b14e-cf4af23ace36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts_before['transcripts'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b058656b-6f9d-459f-9a6a-543e25c6eb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f125c0401a4c2092ab89fde6e1462e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "# 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23970ff1-9313-48b4-91c0-bc275c779110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90d61c2a-b562-43d9-9b11-49cd6d0eb4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import bfloat16\n",
    "import transformers\n",
    "\n",
    "# set quantization configuration to load large model with less GPU memory\n",
    "# this requires the `bitsandbytes` library\n",
    "\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # 4-bit quantization\n",
    "    bnb_4bit_quant_type='nf4',  # Normalized float 4\n",
    "    bnb_4bit_use_double_quant=True,  # Second quantization after the first\n",
    "    bnb_4bit_compute_dtype=bfloat16  # Computation type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab974a07-277d-43be-9aef-eaab1a7a762d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8289ff33b7480d916a48d9872667fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f4519a74ca14e49a830cc1dafc6d401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Llama2 Model\n",
    "model_id_llama2 = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "tokenizer_llama2 = transformers.AutoTokenizer.from_pretrained(model_id_llama2)\n",
    "model_llama2 = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id_llama2,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    ")\n",
    "model_llama2.eval()\n",
    "\n",
    "# Initialize Llama3.1 Model\n",
    "model_id_llama3 = 'meta-llama/Meta-Llama-3.1-8B-Instruct'\n",
    "tokenizer_llama3 = transformers.AutoTokenizer.from_pretrained(model_id_llama3)\n",
    "model_llama3 = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id_llama3,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    ")\n",
    "model_llama3.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f183dec6-3927-47e1-8d61-c488e5d32743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text generator pipeline for Llama2\n",
    "generator_llama2 = transformers.pipeline(\n",
    "    model=model_llama2, tokenizer=tokenizer_llama2,\n",
    "    task='text-generation',\n",
    "    temperature=0.1,\n",
    "    max_new_tokens=500,\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "\n",
    "# Text generator pipeline for Llama3.1\n",
    "generator_llama3 = transformers.pipeline(\n",
    "    model=model_llama3, tokenizer=tokenizer_llama3,\n",
    "    task='text-generation',\n",
    "    temperature=0.1,\n",
    "    max_new_tokens=500,\n",
    "    repetition_penalty=1.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14a461c1-cad1-4efa-b94b-879e69ff1850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt describes information given to all conversations\n",
    "system_prompt2 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for labeling topics.\n",
    "<</SYS>>\n",
    "\"\"\"\n",
    "# Example prompt demonstrating the output we are looking for\n",
    "example_prompt2 = \"\"\"\n",
    "I have a topic that contains the following documents:\n",
    "- Traditional diets in most cultures were primarily plant-based with a little meat on top, but with the rise of industrial style meat production and factory farming, meat has become a staple food.\n",
    "- Meat, but especially beef, is the word food in terms of emissions.\n",
    "- Eating meat doesn't make you a bad person, not eating meat doesn't make you a good one.\n",
    "\n",
    "The topic is described by the following keywords: 'meat, beef, eat, eating, emissions, steak, food, health, processed, chicken'.\n",
    "\n",
    "Based on the information about the topic above, please create a short label of this topic. Make sure you to only return the label and nothing more.\n",
    "\n",
    "[/INST] Environmental impacts of eating meat\n",
    "\"\"\"\n",
    "\n",
    "# Our main prompt with documents ([DOCUMENTS]) and keywords ([KEYWORDS]) tags\n",
    "main_prompt2 = \"\"\"\n",
    "[INST]\n",
    "I have a topic that contains the following documents:\n",
    "[DOCUMENTS]\n",
    "\n",
    "The topic is described by the following keywords: '[KEYWORDS]'.\n",
    "\n",
    "Based on the information about the topic above, please create a short label of this topic. Make sure you to only return the label and nothing more.\n",
    "[/INST]\n",
    "\"\"\"\n",
    "\n",
    "prompt2 = system_prompt2 + example_prompt2 + main_prompt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f0c9e71-4a9b-4bfd-8be5-8888680da698",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt3 = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "You are a helpful, respectful, and honest assistant for labeling topics. Your task is to generate a concise label for each topic provided. Please return only the label, consisting of one word or a short phrase, and nothing more.\n",
    "\"\"\"\n",
    "\n",
    "# Example User Prompt\n",
    "example_prompt3 = \"\"\"\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "I have a topic that contains the following documents:\n",
    "- Traditional diets in most cultures were primarily plant-based with a little meat on top, but with the rise of industrial style meat production and factory farming, meat has become a staple food.\n",
    "- Meat, but especially beef, is the word food in terms of emissions.\n",
    "- Eating meat doesn't make you a bad person, not eating meat doesn't make you a good one.\n",
    "\n",
    "The topic is described by the following keywords: 'meat, beef, eat, eating, emissions, steak, food, health, processed, chicken'.\n",
    "\n",
    "Based on the information about the topic above, please create a short label of this topic. Make sure to only return the label and nothing more.\n",
    "\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "Environmental impacts of eating meat\n",
    "\"\"\"\n",
    "\n",
    "# Main Prompt for Labeling\n",
    "main_prompt3 = \"\"\"\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "I have a topic that contains the following documents:\n",
    "[DOCUMENTS]\n",
    "\n",
    "The topic is described by the following keywords: '[KEYWORDS]'.\n",
    "\n",
    "Based on the information about the topic above, please create a short label of this topic. Make sure to only return the label and nothing more.\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "prompt3 = system_prompt3 + example_prompt3 + main_prompt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02f4971c-685e-4bc0-bb48-a539194681e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KeyBERT\n",
    "keybert = KeyBERTInspired()\n",
    "\n",
    "# MMR\n",
    "mmr = MaximalMarginalRelevance(diversity=0.3)\n",
    "\n",
    "# Text generation with Llama2\n",
    "llama2 = TextGeneration(generator_llama2, prompt=prompt2)\n",
    "\n",
    "# Text generation with Llama3.1\n",
    "llama3 = TextGeneration(generator_llama3, prompt=prompt3)\n",
    "\n",
    "# All representation models\n",
    "representation_model = {\n",
    "    \"KeyBERT\": keybert,\n",
    "    \"Llama2\": llama2,\n",
    "    \"Llama3\": llama3,\n",
    "    \"MMR\": mmr,\n",
    "}\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\", ngram_range=(1, 3))\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cea825a3-225d-4bf2-9750-6177b4a3194d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \"\\n<s>[INST] <<SYS>>\\nYou are a helpful, respectful and honest assistant for labeling topics.\\n<</SYS>>\\n\\nI have a topic that contains the following documents:\\n- Traditional diets in most cultures were primarily plant-based with a little meat on top, but with the rise of industrial style meat production and factory farming, meat has become a staple food.\\n- Meat, but especially beef, is the word food in terms of emissions.\\n- Eating meat doesn't make you a bad person, not eating meat doesn't make you a good one.\\n\\nThe topic is described by the following keywords: 'meat, beef, eat, eating, emissions, steak, food, health, processed, chicken'.\\n\\nBased on the information about the topic above, please create a short label of this topic. Make sure you to only return the label and nothing more.\\n\\n[/INST] Environmental impacts of eating meat\\n\\n[INST]\\nI have a topic that contains the following documents:\\n\\nI have a topic that contains the following documents:\\n- Traditional diets in most cultures were primarily plant-based with a little meat on top, but with the rise of industrial style meat production and factory farming, meat has become a staple food.\\n- Meat, but especially beef, is the word food in terms of emissions.\\n- Eating meat doesn't make you a bad person, not eating meat doesn't make you a good one.\\n\\nThe topic is described by the following keywords: 'meat, beef, eat, eating, emissions, steak, food, health, processed, chicken'.\\n\\n\\nThe topic is described by the following keywords: 'meat, beef, eat, eating, emissions, steak, food, health, processed, chicken'.\\n\\nBased on the information about the topic above, please create a short label of this topic. Make sure you to only return the label and nothing more.\\n[/INST]\\nMeat consumption and environmental impact\"}]\n",
      "[{'generated_text': \"\\n<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\nYou are a helpful, respectful, and honest assistant for labeling topics. Your task is to generate a concise label for each topic provided. Please return only the label, consisting of one word or a short phrase, and nothing more.\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\nI have a topic that contains the following documents:\\n- Traditional diets in most cultures were primarily plant-based with a little meat on top, but with the rise of industrial style meat production and factory farming, meat has become a staple food.\\n- Meat, but especially beef, is the word food in terms of emissions.\\n- Eating meat doesn't make you a bad person, not eating meat doesn't make you a good one.\\n\\nThe topic is described by the following keywords: 'meat, beef, eat, eating, emissions, steak, food, health, processed, chicken'.\\n\\nBased on the information about the topic above, please create a short label of this topic. Make sure to only return the label and nothing more.\\n\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\nEnvironmental impacts of eating meat\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\nI have a topic that contains the following documents:\\n\\nI have a topic that contains the following documents:\\n- Traditional diets in most cultures were primarily plant-based with a little meat on top, but with the rise of industrial style meat production and factory farming, meat has become a staple food.\\n- Meat, but especially beef, is the word food in terms of emissions.\\n- Eating meat doesn't make you a bad person, not eating meat doesn't make you a good one.\\n\\nThe topic is described by the following keywords: 'meat, beef, eat, eating, emissions, steak, food, health, processed, chicken'.\\n\\n\\nThe topic is described by the following keywords: 'meat, beef, eat, eating, emissions, steak, food, health, processed, chicken'.\\n\\nBased on the information about the topic above, please create a short label of this topic. Make sure to only return the label and nothing more.\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\nMeat consumption\"}]\n"
     ]
    }
   ],
   "source": [
    "# Example text data for testing\n",
    "test_text = \"\"\"\n",
    "I have a topic that contains the following documents:\n",
    "- Traditional diets in most cultures were primarily plant-based with a little meat on top, but with the rise of industrial style meat production and factory farming, meat has become a staple food.\n",
    "- Meat, but especially beef, is the word food in terms of emissions.\n",
    "- Eating meat doesn't make you a bad person, not eating meat doesn't make you a good one.\n",
    "\n",
    "The topic is described by the following keywords: 'meat, beef, eat, eating, emissions, steak, food, health, processed, chicken'.\n",
    "\"\"\"\n",
    "\n",
    "test_prompt2 = system_prompt2 + example_prompt2 + main_prompt2.replace(\"[DOCUMENTS]\", test_text).replace(\"[KEYWORDS]\", \"meat, beef, eat, eating, emissions, steak, food, health, processed, chicken\")\n",
    "test_prompt3 = system_prompt3 + example_prompt3 + main_prompt3.replace(\"[DOCUMENTS]\", test_text).replace(\"[KEYWORDS]\", \"meat, beef, eat, eating, emissions, steak, food, health, processed, chicken\")\n",
    "\n",
    "try:\n",
    "    result_2 = generator_llama2(test_prompt2)\n",
    "    print(result_2)\n",
    "    result_3 = generator_llama3(test_prompt3)\n",
    "    print(result_3)\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error during text generation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c86f46d7-b8b8-4292-8cd3-d109e83a5878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39477a119539451289b1f047d04b2269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc97d536aa534f25b9beaf9ed79759bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def precalculate_embeddings(texts, embedding_model):\n",
    "    embeddings_dict = {}\n",
    "    ideologies = texts['channel.ideology'].unique()\n",
    "    for ideology in ideologies:\n",
    "        ideology_texts = texts[texts['channel.ideology'] == ideology]['summary'].tolist()\n",
    "        embeddings = embedding_model.encode(ideology_texts, show_progress_bar=True)\n",
    "        embeddings_dict[ideology] = embeddings\n",
    "    return embeddings_dict\n",
    "\n",
    "# Pre-calculate embeddings for before and after COVID\n",
    "embeddings_before = precalculate_embeddings(texts_before, embedding_model)\n",
    "embeddings_after = precalculate_embeddings(texts_after, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6032fbf-67cc-4a58-81ad-9e5ae90487fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def check_embeddings(embeddings):\n",
    "    for ideology, emb in embeddings.items():\n",
    "        if np.any(np.isnan(emb)) or np.any(np.isinf(emb)):\n",
    "            print(f\"Invalid embeddings detected for ideology: {ideology}\")\n",
    "\n",
    "check_embeddings(embeddings_before)\n",
    "check_embeddings(embeddings_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d0cb2b8-cadb-4312-99f6-e6b883062817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train BERTopic with specific configurations\n",
    "def train_bertopic_for_ideology(texts, ideology, embeddings, vectorizer_model=None, ctfidf_model=None, representation_model=None):\n",
    "    ideology_texts = texts[texts['channel.ideology'] == ideology]['summary'].tolist()\n",
    "    print(f\"Training model for ideology: {ideology} with {len(ideology_texts)} texts.\")\n",
    "    topic_model = BERTopic(\n",
    "        embedding_model=embedding_model, \n",
    "        vectorizer_model=vectorizer_model, \n",
    "        ctfidf_model=ctfidf_model, \n",
    "        representation_model=representation_model,\n",
    "        # Hyperparameters\n",
    "        top_n_words=10,\n",
    "        verbose=True\n",
    "    )\n",
    "    topics, probs = topic_model.fit_transform(ideology_texts, embeddings[ideology])\n",
    "    return topic_model, topics, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3ab7b33-ff51-4d67-b310-0bc0c516b687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before COVID\n",
      "Training model for ideology: BLACK with 454 texts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:04<00:00,  1.07it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:03<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After COVID\n",
      "Training model for ideology: BLACK with 464 texts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:06<00:00,  1.06s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:04<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# # List of ideologies\n",
    "# ideologies = texts_before['channel.ideology'].unique()\n",
    "\n",
    "# Dictionary to store models and topics\n",
    "models_before = {}\n",
    "models_after = {}\n",
    "\n",
    "for ideology in ideologies:\n",
    "    try:\n",
    "        print(\"Before COVID\")\n",
    "        model_before, topics_before, probs_before = train_bertopic_for_ideology(\n",
    "            texts_before, ideology, embeddings_before, vectorizer_model=vectorizer_model, \n",
    "            ctfidf_model=ctfidf_model, representation_model=representation_model\n",
    "        )\n",
    "        models_before[ideology] = (model_before, topics_before, probs_before)\n",
    "        \n",
    "        print(\"After COVID\")\n",
    "        model_after, topics_after, probs_after = train_bertopic_for_ideology(\n",
    "            texts_after, ideology, embeddings_after, vectorizer_model=vectorizer_model, \n",
    "            ctfidf_model=ctfidf_model, representation_model=representation_model\n",
    "        )\n",
    "        models_after[ideology] = (model_after, topics_after, probs_after)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred for ideology {ideology}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5ad0696-1aaf-47a0-9d2b-cbff51218fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic Representations Before COVID for BLACK:\n",
      "\n",
      "Number of Topic: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>KeyBERT</th>\n",
       "      <th>Llama2</th>\n",
       "      <th>Llama3</th>\n",
       "      <th>MMR</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>21</td>\n",
       "      <td>-1_youtuber_youtuber discusses_ashley_reviewer</td>\n",
       "      <td>[youtuber, youtuber discusses, ashley, reviewe...</td>\n",
       "      <td>[90 day fiancé, fiancé, day fiancé, couples, r...</td>\n",
       "      <td>[90 Day Fiancé Review, , , , , , , , , ]</td>\n",
       "      <td>[Reality TV Show Analysis, , , , , , , , , ]</td>\n",
       "      <td>[youtuber discusses, ashley, 90, michael, 90 d...</td>\n",
       "      <td>[The YouTuber discusses the first half of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>0_black_speaker_people_black people</td>\n",
       "      <td>[black, speaker, people, black people, white, ...</td>\n",
       "      <td>[black community, white supremacy, black men, ...</td>\n",
       "      <td>[Racial tensions and conflicts in America, , ,...</td>\n",
       "      <td>[Racism and Black Community Issues, , , , , , ...</td>\n",
       "      <td>[speaker, black people, police, community, inc...</td>\n",
       "      <td>[Hello, I'm Dr. Claude Anderson, and welcome b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>1_speaker_god_people_high</td>\n",
       "      <td>[speaker, god, people, high, bible, book, isra...</td>\n",
       "      <td>[bible, biblical, speaker discusses concept, p...</td>\n",
       "      <td>[Black Identity and Heritage in the Bible, , ,...</td>\n",
       "      <td>[Black Identity and Biblical Interpretation, ,...</td>\n",
       "      <td>[bible, emphasizes, references, israelites, ju...</td>\n",
       "      <td>[The speaker emphasizes the importance of know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "      <td>2_africa_video_ghana_african</td>\n",
       "      <td>[africa, video, ghana, african, viewers, gambi...</td>\n",
       "      <td>[documentary, video, growth, africa web tv, ha...</td>\n",
       "      <td>[African Hair Journeys and Travel Adventures, ...</td>\n",
       "      <td>[African cultural exchange, , , , , , , , , ]</td>\n",
       "      <td>[africa, ghana, african, viewers, gambia, visi...</td>\n",
       "      <td>[The video is a vlog by Juliet, a member of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>3_organization_bethelites_bethel_jt</td>\n",
       "      <td>[organization, bethelites, bethel, jt, jehovah...</td>\n",
       "      <td>[jehovah witnesses organization, bethelites fr...</td>\n",
       "      <td>[Jehovah's Witnesses and Financial Practices, ...</td>\n",
       "      <td>[Jehovah's Witness Critique, , , , , , , , , ]</td>\n",
       "      <td>[organization, bethel, jehovah witnesses, cong...</td>\n",
       "      <td>[The conversation begins with two Jehovah's Wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                            Name  \\\n",
       "0     -1     21  -1_youtuber_youtuber discusses_ashley_reviewer   \n",
       "1      0    190             0_black_speaker_people_black people   \n",
       "2      1    148                       1_speaker_god_people_high   \n",
       "3      2     76                    2_africa_video_ghana_african   \n",
       "4      3     19             3_organization_bethelites_bethel_jt   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [youtuber, youtuber discusses, ashley, reviewe...   \n",
       "1  [black, speaker, people, black people, white, ...   \n",
       "2  [speaker, god, people, high, bible, book, isra...   \n",
       "3  [africa, video, ghana, african, viewers, gambi...   \n",
       "4  [organization, bethelites, bethel, jt, jehovah...   \n",
       "\n",
       "                                             KeyBERT  \\\n",
       "0  [90 day fiancé, fiancé, day fiancé, couples, r...   \n",
       "1  [black community, white supremacy, black men, ...   \n",
       "2  [bible, biblical, speaker discusses concept, p...   \n",
       "3  [documentary, video, growth, africa web tv, ha...   \n",
       "4  [jehovah witnesses organization, bethelites fr...   \n",
       "\n",
       "                                              Llama2  \\\n",
       "0           [90 Day Fiancé Review, , , , , , , , , ]   \n",
       "1  [Racial tensions and conflicts in America, , ,...   \n",
       "2  [Black Identity and Heritage in the Bible, , ,...   \n",
       "3  [African Hair Journeys and Travel Adventures, ...   \n",
       "4  [Jehovah's Witnesses and Financial Practices, ...   \n",
       "\n",
       "                                              Llama3  \\\n",
       "0       [Reality TV Show Analysis, , , , , , , , , ]   \n",
       "1  [Racism and Black Community Issues, , , , , , ...   \n",
       "2  [Black Identity and Biblical Interpretation, ,...   \n",
       "3      [African cultural exchange, , , , , , , , , ]   \n",
       "4     [Jehovah's Witness Critique, , , , , , , , , ]   \n",
       "\n",
       "                                                 MMR  \\\n",
       "0  [youtuber discusses, ashley, 90, michael, 90 d...   \n",
       "1  [speaker, black people, police, community, inc...   \n",
       "2  [bible, emphasizes, references, israelites, ju...   \n",
       "3  [africa, ghana, african, viewers, gambia, visi...   \n",
       "4  [organization, bethel, jehovah witnesses, cong...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [The YouTuber discusses the first half of the ...  \n",
       "1  [Hello, I'm Dr. Claude Anderson, and welcome b...  \n",
       "2  [The speaker emphasizes the importance of know...  \n",
       "3  [The video is a vlog by Juliet, a member of th...  \n",
       "4  [The conversation begins with two Jehovah's Wi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic Representations After COVID for BLACK:\n",
      "\n",
      "Number of Topic: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>KeyBERT</th>\n",
       "      <th>Llama2</th>\n",
       "      <th>Llama3</th>\n",
       "      <th>MMR</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>102</td>\n",
       "      <td>-1_black_organization_people_jehovah</td>\n",
       "      <td>[black, organization, people, jehovah, witness...</td>\n",
       "      <td>[jehovah witnesses, jehovah witness, witness, ...</td>\n",
       "      <td>[Jehovah's Witnesses and Controversial Practic...</td>\n",
       "      <td>[Jehovah's Witnesses Criticism, , , , , , , , , ]</td>\n",
       "      <td>[black, organization, speaker, jehovah witness...</td>\n",
       "      <td>[Hello, I'm Lady C, and welcome to The Critica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0_speaker_god_people_israelites</td>\n",
       "      <td>[speaker, god, people, israelites, judah, bibl...</td>\n",
       "      <td>[israelites, israelite, gentiles, jews, big ju...</td>\n",
       "      <td>[Race, Identity, and Religion in America, , , ...</td>\n",
       "      <td>[Black Hebrew Identity, , , , , , , , , ]</td>\n",
       "      <td>[israelites, judah, bible, israel, argues, heb...</td>\n",
       "      <td>[Dante Fortson is a YouTube creator who challe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>1_africa_african_africans_countries</td>\n",
       "      <td>[africa, african, africans, countries, contine...</td>\n",
       "      <td>[africa, nigeria, african leaders, covid 19, a...</td>\n",
       "      <td>[African Innovation during the Pandemic, , , ,...</td>\n",
       "      <td>[African Innovation During Covid-19, , , , , ,...</td>\n",
       "      <td>[africa, african, africans, countries, contine...</td>\n",
       "      <td>[Hello everyone, welcome back to my channel. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>2_black_speaker_people_black people</td>\n",
       "      <td>[black, speaker, people, black people, communi...</td>\n",
       "      <td>[black community, white supremacy, racism, bla...</td>\n",
       "      <td>[Black Empowerment and Radical Action, , , , ,...</td>\n",
       "      <td>[Black nationalism and vigilantism, , , , , , ...</td>\n",
       "      <td>[speaker, black people, nfac, snoop, black com...</td>\n",
       "      <td>[Hello, welcome to PowerNumbers.com. Today, I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>3_police_incident_officers_woman</td>\n",
       "      <td>[police, incident, officers, woman, dorsey, of...</td>\n",
       "      <td>[police, officer, crime, arrest, officers, vio...</td>\n",
       "      <td>[Racial Violence and Injustice, , , , , , , , , ]</td>\n",
       "      <td>[Police brutality and racial injustice, , , , ...</td>\n",
       "      <td>[police, incident, shot, narrator, case, viole...</td>\n",
       "      <td>[A disturbing incident occurred in a Walmart p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>4_women_men_black_black men</td>\n",
       "      <td>[women, men, black, black men, black women, sp...</td>\n",
       "      <td>[masculinity, new age family, marriage, black ...</td>\n",
       "      <td>[Gender dynamics within the Black community, ,...</td>\n",
       "      <td>[Black male-female relationships, , , , , , , ...</td>\n",
       "      <td>[black men, relationships, white women, family...</td>\n",
       "      <td>[The speaker discusses the controversy surroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                  Name  \\\n",
       "0     -1    102  -1_black_organization_people_jehovah   \n",
       "1      0    120       0_speaker_god_people_israelites   \n",
       "2      1     84   1_africa_african_africans_countries   \n",
       "3      2     68   2_black_speaker_people_black people   \n",
       "4      3     52      3_police_incident_officers_woman   \n",
       "5      4     38           4_women_men_black_black men   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [black, organization, people, jehovah, witness...   \n",
       "1  [speaker, god, people, israelites, judah, bibl...   \n",
       "2  [africa, african, africans, countries, contine...   \n",
       "3  [black, speaker, people, black people, communi...   \n",
       "4  [police, incident, officers, woman, dorsey, of...   \n",
       "5  [women, men, black, black men, black women, sp...   \n",
       "\n",
       "                                             KeyBERT  \\\n",
       "0  [jehovah witnesses, jehovah witness, witness, ...   \n",
       "1  [israelites, israelite, gentiles, jews, big ju...   \n",
       "2  [africa, nigeria, african leaders, covid 19, a...   \n",
       "3  [black community, white supremacy, racism, bla...   \n",
       "4  [police, officer, crime, arrest, officers, vio...   \n",
       "5  [masculinity, new age family, marriage, black ...   \n",
       "\n",
       "                                              Llama2  \\\n",
       "0  [Jehovah's Witnesses and Controversial Practic...   \n",
       "1  [Race, Identity, and Religion in America, , , ...   \n",
       "2  [African Innovation during the Pandemic, , , ,...   \n",
       "3  [Black Empowerment and Radical Action, , , , ,...   \n",
       "4  [Racial Violence and Injustice, , , , , , , , , ]   \n",
       "5  [Gender dynamics within the Black community, ,...   \n",
       "\n",
       "                                              Llama3  \\\n",
       "0  [Jehovah's Witnesses Criticism, , , , , , , , , ]   \n",
       "1          [Black Hebrew Identity, , , , , , , , , ]   \n",
       "2  [African Innovation During Covid-19, , , , , ,...   \n",
       "3  [Black nationalism and vigilantism, , , , , , ...   \n",
       "4  [Police brutality and racial injustice, , , , ...   \n",
       "5  [Black male-female relationships, , , , , , , ...   \n",
       "\n",
       "                                                 MMR  \\\n",
       "0  [black, organization, speaker, jehovah witness...   \n",
       "1  [israelites, judah, bible, israel, argues, heb...   \n",
       "2  [africa, african, africans, countries, contine...   \n",
       "3  [speaker, black people, nfac, snoop, black com...   \n",
       "4  [police, incident, shot, narrator, case, viole...   \n",
       "5  [black men, relationships, white women, family...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [Hello, I'm Lady C, and welcome to The Critica...  \n",
       "1  [Dante Fortson is a YouTube creator who challe...  \n",
       "2  [Hello everyone, welcome back to my channel. T...  \n",
       "3  [Hello, welcome to PowerNumbers.com. Today, I'...  \n",
       "4  [A disturbing incident occurred in a Walmart p...  \n",
       "5  [The speaker discusses the controversy surroun...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyze and compare topics\n",
    "for ideology in ideologies:\n",
    "    model_before, topics_before, _ = models_before[ideology]\n",
    "    model_after, topics_after, _ = models_after[ideology]\n",
    "\n",
    "    model_before\n",
    "    \n",
    "    # Get topic representations\n",
    "    topics_info_before = model_before.get_topic_info()\n",
    "    topics_info_after = model_after.get_topic_info()\n",
    "\n",
    "    print(f\"\\nTopic Representations Before COVID for {ideology}:\")\n",
    "    print(f\"\\nNumber of Topic: {len(topics_info_before)}\")\n",
    "    display(topics_info_before)\n",
    "    # display(model_before.visualize_hierarchy())\n",
    "\n",
    "    print(f\"\\nTopic Representations After COVID for {ideology}:\")\n",
    "    print(f\"\\nNumber of Topic: {len(topics_info_after)}\")\n",
    "    display(topics_info_after)\n",
    "    # display(model_after.visualize_hierarchy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
