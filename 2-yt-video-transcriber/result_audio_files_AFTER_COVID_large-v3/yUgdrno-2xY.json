{
    "yt_video_id": "yUgdrno-2xY",
    "transcripts": [
        {
            "start_time": "",
            "end_time": "",
            "text": "At no other time in world history has humanity had access to the amount of information that it has today.  As access to information has increased, a great many people, myself included, have excitedly anticipated surges of scientific literacy and critical thinking skills to sweep across the globe.  After all, if people have access to nearly limitless high-quality educational content online, they are bound to learn from it, right? ",
            "speaker": {
                "name": "Speaker 1"
            }
        },
        {
            "start_time": "00:00:25,260",
            "end_time": "00:00:25,320",
            "text": "No.  Not this time.  It's totally me. ",
            "speaker": {
                "name": "Speaker 0"
            }
        },
        {
            "start_time": "00:00:28,040",
            "end_time": "00:00:33,960",
            "text": "Well, that view, as plenty of my peers have pointed out, is probably overly optimistic.  We do have access to more information than ever before, yes, but not just the good stuff.  Misinformation has become more accessible than ever as well, and much of the time, misinformation spreads faster than truth.  In my optimism, I've imagined a world which is increasingly united, not by cultural customs, government, or even religious preferences, but by a shared knowledge of the well-attested facts of our universe.  Where we came from and how we became human, as explained by evolution by natural selection.  How our minds work, as explained by experimental psychology.  What we've done in our past and why, as explained by historical scholarship.  How humans and other animals operate physically, as explained by the field of biology.  You get the idea.  In many crucial ways, we already are united by that shared knowledge.  Advances in medicine, agriculture, communication, transportation, and countless other enterprises are made by the efforts of a diverse global scientific community.  Still, though, it's evident that humanity, not just when divided by oceans and borders, but also when separated by little more than preferences in TV news programming, lacks a common, factual reality.  The impact of our lack of a shared reality has, most recently, led to widespread disagreement over whether a virus, which has been well evidenced to have caused the deaths of millions worldwide, is any threat at all.  This, as could be expected, has exacerbated the problem.  Without a shared understanding of the reality in which we live, We're unable to collectively make decisions for the public good.  We need to be able to make those decisions effectively, so we need a shared reality.  The problem is, no one, myself included, knows enough to flatly say these are the facts on every important issue we face.  No one source is capable of teaching us all what to think.  That's why I propose we look to those who have managed to come to a fruitful shared understanding of reality across dividing lines, the global scientific community, to learn for ourselves how to think in a way which reliably leads to truth.  In his final book, The Demon-Haunted World, Carl Sagan described a kind of toolkit which scientists, as a part of their training in any field, acquire for use in evaluating new claims or ideas.  If, as Sagan said, a new idea survives examination by these tools, it's granted warm, but tentative acceptance.  This is Sagan's famous baloney detection kit.  In it are nine rules for skeptical thinking, which I'll now present one by one.  Wherever possible, there must be independent confirmation of the facts.  Every source is vulnerable to bias, conflicts of interest, and honest mistakes, so fully trusting a single source can sometimes lead us to false beliefs.  To avoid this, we examine whether a claim has been backed up by multiple independent sources.  In the case of homeopathy, for example, there's a committed group of proponents which claim homeopathy can alleviate disease in their experience.  However, When homeopathic substances have been tested through rigorously controlled scientific experimentation by multiple independent research groups, this has consistently failed to be confirmed.  If homeopathy really has medical benefits, anyone should be able to perform a well-controlled experiment and see that result.  Until such a time as a claim like the medical efficacy of homeopathy can be independently confirmed, we did not accept it.  Encourage substantive debate on the evidence by knowledgeable proponents of all points of view.  If something is true, it can withstand scrutiny, even from multiple perspectives.  Conversely, if a proposition is not true, having knowledgeable people of various perspectives examine it together is an effective way to uncover shortcomings which may have been missed by an individual.  The key to this tool, in my opinion, is knowing what substantive debate looks like and who is knowledgeable on whatever the topic may be.  Debate which includes name-calling, rhetorical trickery, misleading statements, distracting from the topic, or anything else which serves to steal focus from the topic and place it instead on the individuals in the debate, or anything else besides the topic at hand, isn't substantive.  As for how to know who is knowledgeable on a given issue, that can take some work.  Those who have credible degrees related to a topic or publish work on a topic in peer-reviewed journals usually qualify, I'd say, but that's not the only measure of knowledgeability.  Those who are consistent in citing credible sources, avoiding fallacious arguments, and utilizing the toolkit we're discussing right now can qualify as well.  Do not accept arguments from authority.  As Sagan said in The Demon Haunted World, arguments from authority carry little weight.  Authorities have made mistakes in the past.  They will do so again in the future.  Perhaps a better way to say it is that in science there are no authorities.  At most, there are experts.  Even if an authority figure puts forth a claim, we must still examine that claim with the utmost scrutiny before accepting it because even authorities are fallible.  Sagan took special care to stress this point in his writing as well as his interviews. ",
            "speaker": {
                "name": "Speaker 1"
            }
        },
        {
            "start_time": "00:05:47,680",
            "end_time": "00:05:50,620",
            "text": "Science is more than a body of knowledge.  It's a way of thinking, a way of skeptically interrogating the universe with a fine understanding of human fallibility.  If we are not able to ask skeptical questions, to interrogate those who tell us that something is true, to be skeptical of those in authority, then we're up for grabs for the next charlatan, political or religious, who comes ambling along. ",
            "speaker": {
                "name": "Speaker 0"
            }
        },
        {
            "start_time": "00:06:19,340",
            "end_time": "00:06:21,000",
            "text": "Spin more than one hypothesis.  If there's something to be explained, think of all the different ways in which it could be explained.  Then think of tests by which you might systematically disprove each of the alternatives.  What survives, the hypothesis that resists disproof in this Darwinian selection among multiple working hypotheses, has a much better chance of being the right answer than if you had simply run with the first idea that caught your fancy.  As tempting as it can be to look at the available data, connect the dots however seems most plausible or affirming of our existing biases, and consider the matter solved, that's not an effective way to figure out the best explanation of the data.  The practice of positing multiple hypotheses, testing them all, and then only upholding any hypotheses that survive a process of elimination allows us to come to much more useful and accurate explanations of the data.  It cuts through our own assumptions and biases much better than the alternative of going with our first guess.  Try not to get overly attached to a hypothesis just because it's yours.  It's only a way station in the pursuit of knowledge.  Ask yourself why you like the idea.  Compare it fairly with the alternatives.  See if you can find reasons for rejecting it.  If you don't, others will.  While I think this concept is one of the easiest on this list to understand, it's almost definitely the hardest to put into practice.  Humans are not rational.  We cling to our ideas and positions forcefully, even conflating our entire identity or personal character with some of them to the point where if they're challenged, we feel personally attacked.  What we have to remember, though, is that this process of skeptical inquiry is not aimed at hurting us by stripping away cherished beliefs.  It's a process we design to help us reach an accurate, useful understanding of our world, and it works.  As much as we may try not to get irrationally attached to certain ideas of ours, it's still going to happen because that's how humans usually operate.  However, you might have noticed that the other tools in this toolkit are designed to cancel out human bias in some way.  We may never be able to psychologically overcome our innate tendency to think in a biased way, but we can, in utilizing the other tools mentioned here, subject our ideas to experimentation and the scrutiny of others in order to overcome our biases practically.  While not always a pleasant or popular undertaking, humbling ourselves enough to discard ideas which don't withstand scrutiny is, in my view, a social responsibility.  We act on our beliefs.  If our beliefs are wrong, we may act in a way which causes unnecessary harm to others.  So if we care to avoid causing unnecessary harm to others, we've got to get into the practice of discarding beliefs, however cherished, if they do not stand in the face of the evidence.  I'll have Sagan say a final word on this. ",
            "speaker": {
                "name": "Speaker 1"
            }
        },
        {
            "start_time": "00:09:12,760",
            "end_time": "00:09:21,300",
            "text": "I don't propose to tell anybody what to believe, but for me, believing when there's no compelling evidence is a mistake.  The idea is to withhold belief until there is compelling evidence.  And if the universe does not comply with our predispositions, okay, then we have the wrenching obligation to accommodate to the way the universe really is.  We demand the most rigorous standards of evidence, especially on what's important to us.  So if some guy comes up to me, a channeler or a medium, and says, I can put you in touch with your parents.  Well, because I want so terribly to believe that, I know I have to reach in for added reserves of skepticism because I'm likely to be fooled and much more minor to have my money taken. ",
            "speaker": {
                "name": "Speaker 0"
            }
        },
        {
            "start_time": "00:10:05,680",
            "end_time": "00:10:06,380",
            "text": "Quantify.  If whatever you're explaining has some measure, some numerical quantity attached to it, you'll be much better able to discriminate among competing hypotheses.  What is vague and qualitative is open to many explanations.  Of course, there are truths to be sought in the many qualitative issues we are obliged to confront, but finding them is more challenging.  Language isn't as precise as mathematics.  Numbers have immutable definitions and relationships to each other, but words don't.  This is why explanations which rely on numerical quantities and relationships can be much more precise than those which rely on language alone.  Let me explain this one by way of example.  When attempting to discern how someone's metabolism is functioning, researchers may subject them to light physiological stress, such as walking on a treadmill.  Then, instead of asking the person, how do you feel, or what's your energy level, they measure the person's rate of oxygen intake, which gives them the information necessary to calculate how quickly their metabolism, using oxygen, converts the chemical energy stored in their food into energy usable to the body.  Information about the person's metabolism can then be communicated numerically and with great precision, rather than by subjective self-reports of tiredness.  If there's a chain of argument, every link in the chain must work, including the premise, not just most of them.  This is very straightforward.  If there's just one logical inconsistency or unsubstantiated claim within an argument, the whole thing breaks down.  I most often see this tool ignored when larger theories rather than individual arguments are involved.  Someone will hold to a particular view which is based on a great number of premises.  Then, when one of those premises is shown to be false, the person claims they can keep believing in their view because the majority of their premises are still intact, even though the argument for their view breaks down without all their premises remaining intact.  Within an argument, premises are the building blocks.  Together, they create something larger than themselves, but when just one of them is undermined, the structure falls apart.  Occam's razor.  This convenient rule of thumb urges us, when faced with two hypotheses that explain the data equally well, to choose the simpler.  Is an explanation which makes three assumptions more likely to be true than one which makes only two?  Of course not.  If something can be explained with two assumptions, a third is unnecessary.  If it's truth we're after, making assumptions is to be avoided whenever possible.  In practice, this means tossing out hypotheses which explain the data in a way which is more complicated than necessary.  Here's a clip of Sagan utilizing Occam's Razor while discussing the data involved in reports of alien encounters. ",
            "speaker": {
                "name": "Speaker 1"
            }
        },
        {
            "start_time": "00:12:52,680",
            "end_time": "00:12:52,980",
            "text": "What is that?  Before you leave UFOs, tell me about you and Professor Mack.  John Mack is a professor of psychiatry at Harvard who I've known for many years.  And many years ago, he asked me, what is there in this UFO business?  Is there anything to it?  And I said, absolutely nothing, except, of course, for a psychiatrist.  He is a psychiatrist.  Well, he looked into it and decided that there was so much emotional energy in the reports of people who claimed to be abducted that it couldn't possibly be some psychological aberration, that it had to be true.  He believed his patients.  I do not believe his patients.  Many of these stories are about waking up from a deep sleep and finding your bed surrounded by three or four short, doer, gray, and sexually obsessed beings.  But many people awaken from a nightmare with profound emotional force.  That doesn't mean that the nightmare is true.  It means something went on inside our head. ",
            "speaker": {
                "name": "Speaker 0"
            }
        },
        {
            "start_time": "00:14:03,580",
            "end_time": "00:14:07,960",
            "text": "Always ask whether the hypothesis can be, at least in principle, falsified.  Propositions that are untestable, unfalsifiable, are not worth much.  Consider the grand idea that our universe and everything in it is just an elementary particle, an electron, say, in a much bigger cosmos.  But if we can never acquire information from outside our universe, is not the idea incapable of disproof?  You must be able to check assertions out.  Inveterate skeptics must be given the chance to follow your reasoning, to duplicate your experiments, and see if they get the same result.  If there's no conceivable way to put an idea to the test, It isn't one from which we can build any meaningful explanations.  An unfalsifiable proposition is one which can only have explanatory power if flatly assumed true, and of course, we're not in the business of making unnecessary assumptions in search of truth.  For those still unsure of this tool, let's consider a world where, instead of accepting ideas when they're evidence to be true, we accept ideas when they can't be proven false.  Well, I assert that there's someone standing behind you right now.  You say you've turned around and you can't see them?  Well, that's just because the person is fast and they can stay out of your field of vision no matter how you move.  Your back is against a wall?  Oh, well, they can just move through solid objects, no problem.  No one else says they can see them?  Well, that's just because they're being paid off by big... standing behind you, guy.  No matter how you object to my claim, in a world where we accept claims because they can't be falsified, you've got to accept it no matter how absurd it gets.  I could claim that the universe rests on the back of a turtle, or that you popped into existence 10 seconds ago with all of your memories, and you have to accept it.  Any and every idea that couldn't be proven wrong would have to be accepted in such a world.  and that would lead to complete absurdity.  Ensuring that our hypotheses are falsifiable keeps us grounded in the world where evidence is required for an idea to be considered true.  Sagan's complete baloney detection kit, as detailed in The Demon Haunted World, goes on to cover multiple logical fallacies, as well as some notes on experimental design.  But for the sake of keeping this video more concise and accessible, I've chosen to stop here.  If you'd like to read through the entire thing for yourself, and I do encourage you to do so, you'll find the full version linked in the description.  As you utilize these tools for yourself, remember Sagan's concluding words on the subject. ",
            "speaker": {
                "name": "Speaker 1"
            }
        }
    ]
}