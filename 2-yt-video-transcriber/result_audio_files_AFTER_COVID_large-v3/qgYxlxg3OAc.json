{
    "yt_video_id": "qgYxlxg3OAc",
    "transcripts": [
        {
            "start_time": "",
            "end_time": "",
            "text": "So did you have a bad feeling about this video?  Well, whether your gut feeling was a good one or a bad one, today we're going to try and put your intuition to the test.  And we're going to try and see if we can figure out why we sometimes have those gut reactions that we do.  Anyway, welcome back to Myth Mondays.  You now live in a post-apocalyptic future and you are the leader of an army of Terminators.  And you're fighting a war against other people with... armies of terminators.  it's a bloody war with lots of death and destruction but when your terminators return back from battle they show that they have been heavily heavily wounded in these areas.  here now you have limited funds available to add extra armor and protection to your terminator models.  my question to you is where would you apply that extra armor?  well if your gut feeling is telling you that we should be applying extra armor to those damaged areas marked in red then your gut feeling is letting you down.  and here's why.  Meet Abraham Wald, a Hungarian mathematician who was asked to solve a very similar problem during World War II.  Now at that time, researchers from the Centre of Naval Analysis had been asked to look at their bombers, and these dots in red show the places that their bombers showed most damage when they returned home.  Now as a result of that, those researchers recommended strengthening the bombers in these areas.  But Abraham Wald disagreed.  He understood survival bias, which in this instance means only concentrating your efforts on the planes that made it back home.  Wald realized that planes that took heavy damage to these areas marked in red were still able to fly home.  It was the planes that took damage to the other areas that were not, so it was the other areas that needed the reinforcement.  Now, if you did get it wrong, don't worry about it.  Our gut reaction can often steer us wrong.  And as will be the case with all the examples in this video, I'm sure that given enough time, you'll be able to work out the correct answer.  But if you did get it wrong, you've been a victim of your own system one thinking.  And we will explain that more later on in this video.  But for now, another example.  So you're sat in a saloon in the old west, you're just kicking back and chilling out and then suddenly Billy the Kid appears and says, you're going to die boy.  Actually that's the best impression of Billy the Kid you'll ever hear, prove me wrong.  But Billy the Kid is a firm man and he's not going to shoot you dead without giving you a chance to do something about it.  He flips two coins, he catches them both, he tells you that one of these coins is a tail and if you can tell him the probability of both coins being a tail, you get to live.  So what does your gut feeling tell you about that?  What does your intuition tell you?  How many of you just couldn't help but instantly think of 50%?  Well, if you did, you'd be going home in one of these.  Your gut feeling was wrong.  We can show why by using a simple grid like this.  Billy tossed two coins in the air.  The first one I'm going to represent as blue, and it could have landed as heads or tails.  The second one I'm going to represent in red, and that also could have landed heads or tails.  Now, if we complete this grid, we can look at all four possible ways that these coins could have landed.  But let's remember that Billy the Kid told us that one of the coins landed on a tail, which means it must have been one of these three combinations.  It's simply not possible anymore for it to have been this one.  So now we're in the situation where we have three possible combinations where one of the coins could have been a tail, but only one of these three has the other coin as also being the tail.  So therefore the chance of that other coin being a tail is one in three.  Now, yet again, if you said 50%, you're a victim of your own system on thinking, but the answer actually is one in three.  And it's very, very easy to prove that to yourself.  Yeah, so this is me in my living room, in my pyjamas, and I tried to toss these two coins 100 times.  And of course, each time, I recorded the results.  But I can't count, so I accidentally tossed them 101 times, but that's not a problem.  We can see from the scorecard that 25 of those times, they both landed heads up.  We removed that from the 101 to leave us with 76 coin tosses, where at least one of them was a tail.  And out of those, 26 showed that they were both a tail, which gives us our 1 in 3.  So what exactly is system one thinking?  Well, system one thinking does much of our cognitive workload through the day.  It's super, super fast at processing information and recognizing patterns.  And it derives context from our own memories and past experiences.  So in the two examples we've looked at so far with the robot, we can't help but remember that we fix things that are broken.  So therefore, our gut reaction is to make sure that we put the extra armor on the damaged parts of that robot.  We are so used to talking about a coin having a 50% chance of landing heads or tails that in that second example, we couldn't help but just instantly think of 50% as being the answer.  Now, I want you to have a look at this tree, and thank you, Craft Tequila, for the image.  Now, while you're looking at the tree, you'll slowly start to realize that there's a gorilla and there's a tiger in the picture, but how long will it take you to realize that there's also a couple of fish?  And when you're looking at this picture, you will instantly recognize one of two animals.  And it shouldn't take you too much longer before you realize there are indeed two animals.  Now, our system one thinking is responsible for seeing that initial image.  But in the background, working away more slowly but more deliberately is our system two thinking.  Now, the two aren't independent of each other.  They do communicate, which is why in a short amount of time, we do get to see all the images.  But employing our system two thinking deliberately is hard work.  And to prove that, watch this.  In a few seconds, I'm going to ask you to look at the windows of this house, and I'm going to start turning the lights on and off.  What I really need you to do is pay attention.  This is going to be difficult, but by the end of the clip, I want you to tell me which window had its light turned on most often.  Now, this really might be difficult to count because it does go quite quickly, but I really, really want you to concentrate.  It's not on for that long.  Can you figure out which window has its light turned on more often?  Really concentrate.  Good luck.  Okay, well, the answer is the top left window and the bottom right window were both turned on eight times each, which was more than the other two, but that wasn't really the question I wanted to ask.  The question I wanted to ask was this.  The question I really want to ask is, how many of you noticed while you were doing that that the question in the top right-hand corner turned from this... to me telling you that you smell of poo.  It's a joke, by the way.  Well, if you did miss that, you might want to wind back a little bit and check that I'm not pulling your leg.  And if you didn't miss it, were you really paying 100% attention to those windows?  Because if you were, you would have been employing your system two thinking, which tends to blind us to things that we're not putting our concentration into.  Ask yourself how often it actually is that accidents are caused where drivers, careful drivers, pull out of a junction into the path of an oncoming cyclist.  Now, much of the time, this isn't because they're not paying attention.  It's because they are concentrating very, very hard using their System 2 thinking, but they are concentrating on oncoming traffic.  They're not looking for the cyclist.  Now, we don't really talk about System 2 thinking much when we're talking about intuition and gut feeling.  That's more about System 1.  And we've already said that System 1, yes, it processes information at high rates, it recognises patterns, but it also derives context and meanings from our own experiences and memories.  But what happens if our own memories are not as reliable as we like to think?  There has been an absolutely hideous crime, but you are the great detective here to solve it.  You head down to the police station, and after checking CCTV, you realise there have been two witnesses.  The only problem is these witnesses give different versions of the event.  Who are you going to believe?  Witness A is Mr.  Hunkle McBunkfunkle.  He's extremely confident.  he can recall all the events.  You see, since the crime, he has been reliving it every single night by telling all his friends and family.  He's very confident.  he's got it down pat by now.  Witness B is a Mr.  Nip Twister McButther.  Now, he lives alone.  He's not had a chance to retell the story to anybody.  In fact, he's tried to distance himself from the event by doing things like housework and alphabetically sorting his packet of M&Ms.  So he's less confident in his ability to recall the details correctly.  Now as a detective, what does your intuition tell you?  Which of those two witnesses would you find more reliable?  My gut feeling would have told me to go for the witness who's been telling the story over and over more often.  They're probably less likely to have forgotten those small details.  But I might be wrong.  This article here from the Criminal Justice magazine references work carried out by Dr Donna Bridge and states how eyewitness testimony can not always be as reliable as we might think it is.  Now you may be familiar with the term remember remembering.  but if you're not the main findings from Dr Bridge's work are on the screen right now.  Essentially what she showed us.  when we try to remember an event we're not actually remembering the event itself.  We are remembering the last time we remembered it.  In fact, she showed that the more often we remember something, the more errors can creep in.  So just like a game of Chinese whispers, the final memory may be very, very different from the original event.  Now, just saying that is all well and good, but how did she go about showing it?  Well, Dr.  Bridge started off on day one by showing everybody a grid on a computer screen that looks like this.  She then placed a dot randomly on the grid and asked the participants to try and remember exactly where that dot was.  Now, later on that day, the participants were asked to guess where they thought that red dot was, and they typically got it very close.  For example, where this green dot is now.  Now, remember, this would have been the first time that they were asked to accurately remember that event.  But then day two comes and they're asked to remember the location again, but this time the participants typically put the dot somewhere around here.  This signals that they are remembering their choice from the day before as opposed to the actual original event.  And this trend continued, almost like the original event in their memory had been overwritten by the previous times they've tried to remember it.  So it turns out that witness testimony might not be as reliable as our gut feeling might tell us.  And in fact, our memory can be messed with in a few different ways.  The misinformation effect refers to the fact that if we're given new information about an event after that event has occurred, it can somehow interfere with our memories, making our memories less accurate.  For example, all it might take is an impressionist or a TV host or a famous actor misquoting a movie line on television.  Luke, I am your father.  And suddenly people will start to believe that that was the actual correct line.  And they'll reinforce that to themselves every time they remember it, up until the point that when they actually realize the correct line was, no, I am your father, that they'll be amazed.  Now if that new piece of information is delivered on a large public platform and accessed by a lot of people, then we can get a lot of people very, very confused and can end up with something like the Mandela Effect, which will be the subject of another video.  But for now, back to system one thinking.  How easy is it for us to override it?  And what techniques can we use to do that?  The cognitive reflection test is a popular test used by researchers to test a person's ability to consciously override the tendency to go towards system one thinking.  So let's give it a go.  Pause the video now, have a look at the questions and see what your gut feeling is about each one of these answers.  Then, if you want, try and work it out and think a little bit more about it and see if you still come up with the same answer.  Now, I'm going to crack on in about three seconds, so do make sure you pause it.  Okay, hopefully you've had a go.  Now let's go and have a look at what the typical answers are when we rely on our intuition.  Now when psychologist Shane Frederick gave this test to a large number of participants, he found that common answers to these questions were 10 cents, 100 minutes, and 24 days.  But in fact, if you pause a video and engage your system to thinking, these are the answers you should have come up with.  Okay, so again, that's all well and good, but what has that got to do with actually manipulating the type of thinking that somebody's using?  Well, take a look at the text in italic on this screen.  Now, I know it's harder to read, and that is the point, but please do read it.  I'm going to pause for 10 seconds just to give you the chance.  So the very fact that we've changed the font into a less common one means that it's more difficult for our System 1 thinking to recognize the patterns.  And we have to use our System 2 thinking to plow through the text.  But while doing that, we're paying more attention to detail.  So the candidates who sat the test with that more difficult font tended to do a lot better.  So if we want to make something harder to read, it turns out that altering the font is more important than actually altering the words themselves.  Perhaps this is why some companies put complicated and unfair clauses inside the small print, because we know that that engages our system two thinking and we're less likely to read it.  Now, the above text is a nice, easy to read font and should only engage our system one thinking.  Have a go at reading this.  So the conclusion we can draw from this is if you really want somebody to pay attention to something, present it in a less easily accessible form.  Stop them using their system one thinking, make them engage their system two, and they'll take on much more detail.  Now, if what I'm saying is correct, because you were relying less on system one thinking when you were reading this, you should have been more likely to spot the fact that I deliberately duplicated the word this.  However, when you were reading this, you were relying more on system one thinking, so you would have been less likely to realize that I deliberately duplicated the word the.  So our intuition, our gut feeling really might not be as reliable as we'd like to think.  It is based on past experiences.  It can be manipulated.  And here's another example of how.  So let's test your gut feeling one more time.  Do you think there are more or less than 3,000 baked beans in this regular tin?  Now hopefully your gut feeling is giving you an answer to that question, but that's not the question I really want to ask.  The question I want to ask you is, how many baked beans do you think are in that can?  See if you can guess it to the nearest hundred.  Now I know that's a very difficult question to answer, so there's going to be a wide range of responses.  What did you think of?  Let me know in the comments.  Was it 2,500?  3,200?  Was it 4,000?  Was it 2,000?  Well, let's find out what the actual answer is.  Well, actually, there are only 465 beans in an average tin, nowhere near that 3,000.  But if your guess was in or around that 3,000 mark, then you've let your gut feeling be controlled by something called anchoring.  Anchoring is a form of cognitive bias, which makes us rely far too heavily on the first piece of information we're given about a subject.  So for example, here, I gave you the number 3000, which in most cases will definitely have influenced your guess.  And how many times have we all been a victim of that?  How many times have I, for example, logged onto Amazon and seen a big red sales sign across a product telling me that there's 50, 60, 70% off?  Well, studies have shown that when we get that information first, it weighs far too heavily in our judgment, more heavily even than looking at the specifications and the reviews about the product.  And I've bought some right old junk, honestly.  Anyway, back to intuition.  What else can affect it?  How about the availability bias?  In 1973, Tversk... Tversk... In 1973, T... In 1973, these two guys here did an experiment that demonstrated the availability bias.  They rounded up a large group of people with more easily pronounceable names and they asked them this simple question.  What is more common, words beginning with the letter K or words with the letter K as the third letter?  Now in reality, the letter K appears as the third letter in a word far, far more commonly than it does the first letter.  However, because it only takes System 1 thinking to think of words that begin with the letter K, for example kangaroo and kettle, but it requires much more effort to think of words that have the letter K as the third letter, this is how people tended to vote.  So the availability bias tells us that our gut reactions relies far too heavily on information that's very easy to bring to mind, and that includes recent memories.  Now, companies take advantages of this all the time.  For example, lottery companies are constantly shoving pictures of winners' faces down our throats, making it really easy for us to recall those images and gain a false sense of how likely it actually is for us to win the lottery.  Now, at the start of this video, I did ask you if you had a bad feeling about it, and maybe you did, maybe you didn't, and that'll be based on your own personal experiences.  But for me, making and researching this video has taught me that I really need to be more careful and look out deliberately for the tactics that companies are using to try and manipulate my own gut feeling and my own intuition, and there'll definitely be a follow-up video on this.  But for now, if you want to vote on future topics for Myth Monday, if you want to vote on future topics for my other channel, Conspiracy Cats, and if you want access to a monthly blooper video, which will contain outtakes and behind the scenes across all my channels, then please consider hitting that join button below.  But if you don't, never mind, and I will see you next time. ",
            "speaker": {
                "name": "Speaker 0"
            }
        }
    ]
}