{
    "yt_video_id": "1dDhqX3txf4",
    "transcripts": [
        {
            "start_time": "",
            "end_time": "",
            "text": "Today's surveillance video systems are getting paired with a monitoring technology known as video analytics, in which computers don't just record what we're doing, but actually understand and monitor and judge. ",
            "speaker": {
                "name": "Speaker 0"
            }
        },
        {
            "start_time": "00:00:11,360",
            "end_time": "00:00:19,120",
            "text": "What if we could weave the most advanced machine learning, computer vision, and AI into the very fabric of a store, so you never have to wait in line?  We call it Just Walk Out Technology. ",
            "speaker": {
                "name": "Speaker 1"
            }
        },
        {
            "start_time": "00:00:23,340",
            "end_time": "00:00:24,040",
            "text": "But here's the catch.  These smart cameras pose a major threat to our privacy.  Until recently, when we walked into a store, we expected to be recorded.  But unless something dramatic goes down, the videos weren't closely monitored.  Now the cameras won't just record objects and actions.  They'll actually analyze them.  So companies like Microsoft, as you can see in this video, advertise their ability to track emotions.  They say to enhance security.  But of course, we know this technology in the hands of police could supercharge the biased ways that many of them already operate.  That same technology has been used to try to identify fashion trendsetters.  I'm a fashion editor out here with New Balance to spot exceptional outfits on the street.  And the way we're doing that actually is with artificial intelligence.  But it could also be used, for example, to identify everybody wearing a hoodie or carrying a pride flag or wearing a religious garb.  In the hands of the government, this technology could become a way to track and chill dissent.  Not only will these AI smart cameras let the authorities monitor video live, it'll also let them go back and comb through hundreds of thousands of hours of stored video.  That's what this company called BriefCam is showing here. ",
            "speaker": {
                "name": "Speaker 0"
            }
        },
        {
            "start_time": "00:01:28,860",
            "end_time": "00:01:38,700",
            "text": "Looking for something specific, quickly pinpoint objects of interest by type, gender, size, color, direction, speed, and more. ",
            "speaker": {
                "name": "Speaker 2"
            }
        },
        {
            "start_time": "00:01:39,660",
            "end_time": "00:01:49,560",
            "text": "And they can do that not just with cars, but this kind of search could be used to find all women, all black people, all young people, people who fit any of the categories that the AI cameras will increasingly be able to recognize.  And this technology is not just going to be used in the  U.S.,  but also by authoritarian governments abroad, like China, which is subject to its Uyghur population to intense surveillance.  Basically, this is a technology that turns our cameras from dumb recording devices into smart AI security guards that will be watching us at every moment.  We need to pass strong privacy protections to make sure we don't end up in a world where we feel constantly monitored, where the government abuses this technology against people of color and other vulnerable communities, and where we feel like we're monitored from the moment we leave our house until we return at night. ",
            "speaker": {
                "name": "Speaker 0"
            }
        }
    ]
}